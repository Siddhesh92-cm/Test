async def run_agent_and_collect(agent: Any, sub_question: str) -> str:
    """Run agent and collect ALL data, even when hitting recursion limits"""
    recursion_limit = 5  # Matches your configured limit
    all_chunks = []
    collected_content = []

    try:
        # Stream agent responses (original logic)
        async for chunk in agent.astream(
            {"messages": [{"role": "user", "content": sub_question}]},
            {"recursion_limit": recursion_limit},
            stream_mode="updates"
        ):
            all_chunks.append(chunk)
            logger.info(f"Agent step chunk: {chunk}")

            # Extract content from all possible locations
            agent_data = chunk.get("agent", {})
            messages = agent_data.get("messages", []) if isinstance(agent_data, dict) else []
            
            for msg in messages:
                content = msg.get("content") if isinstance(msg, dict) else getattr(msg, "content", None)
                if content and str(content).strip():
                    collected_content.append(str(content).strip())

            output = chunk.get("output")
            if output:
                content = output.get("content") if isinstance(output, dict) else getattr(output, "content", None)
                if content and str(content).strip():
                    collected_content.append(str(content).strip())

    except Exception as e:
        logger.warning(f"Agent stopped early: {str(e)}")
        # Continue to return collected data even if error occurred

    # Return all valid content or fallback message
    if not collected_content:
        return "No information found about this clinical trial."
    
    # Filter out very short/unhelpful messages
    filtered_content = [
        c for c in collected_content 
        if len(c) > 20 and not c.startswith(("I don't know", "Sorry", "Error"))
    ]
    
    # If we have filtered content, return it with error appended if exists
    if filtered_content:
        return "\n\n".join(filtered_content)
    
    # If only errors were captured, return them
    error_messages = [c for c in collected_content if "Error" in c or "recursion limit" in c]
    if error_messages:
        return f"Research incomplete: {error_messages[-1]}"
    
    return "No information found about this clinical trial."


async def research_sub_query(
    sub_question_data: Dict[str, Any],
    original_query: str,
    refined_query: str,
    server_type: ServerType,
) -> Dict[str, Any]:
    """Wrapper that preserves all research attempts"""
    sub_question = sub_question_data.get("question", "")
    tool_names = sub_question_data.get("potential_tools", [])
    priority = sub_question_data.get("priority", 1)

    try:
        # Original tool setup logic
        if ToolSelector[server_type]["data_type"] == "MCP":
            server_url = ToolSelector[server_type]["tools"]
            if not server_url:
                return {
                    "sub_question": sub_question,
                    "answer": "Error: No MCP server URL available"
                }

            async with streamable_http_client(server_url) as (read_stream, write_stream, _):
                async with ClientSession(read_stream, write_stream) as mcp_session:
                    await mcp_session.initialize()
                    all_tools = await load_mcp_tools(mcp_session)
                    tools = [tool for tool in all_tools if tool.name in tool_names]
                    
                    context = f"Original query: {original_query}\nRefined query: {refined_query}\n"
                    agent = create_research_agent(
                        tools=tools,
                        sub_question=sub_question,
                        context=context,
                        server_type=server_type
                    )
                    answer = await run_agent_and_collect(agent, sub_question)

        # Non-MCP case
        else:
            all_tools = ToolSelector[server_type]["tools"]
            tools = [tool for tool in all_tools if tool.name in tool_names]
            context = f"Original query: {original_query}\nRefined query: {refined_query}\n"
            agent = create_research_agent(
                tools=tools,
                sub_question=sub_question,
                context=context,
                server_type=server_type
            )
            answer = await run_agent_and_collect(agent, sub_question)

        return {
            "sub_question": sub_question,
            "answer": answer if answer else "No data found"
        }

    except Exception as e:
        logger.error(f"Error researching {sub_question}: {str(e)}")
        return {
            "sub_question": sub_question,
            "answer": f"Research error: {str(e)}"
        }

